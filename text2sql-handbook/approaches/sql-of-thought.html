<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Building SQL-of-Thought: Multi-Agentic Text-to-SQL with Guided Error Correction | Text2SQLHub</title>

  <!-- Fonts -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&family=Fira+Code:wght@400;500&display=swap" rel="stylesheet">

  <!-- Tailwind CSS -->
  <script src="https://cdn.tailwindcss.com"></script>

  <!-- Custom CSS -->
  <link rel="stylesheet" href="../assets/css/main.css?v=12">

  <!-- Prism.js for code highlighting -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
</head>
<body>

  <!-- Navigation -->
  <nav class="navbar">
    <div class="container">
      <div class="flex items-center justify-between py-4">
        <a href="../index.html" class="text-2xl font-bold text-blue-600 hover:opacity-80 transition-opacity">
          Text2SQL<span class="text-gray-200">Hub</span>
        </a>
        <div class="hidden md:flex items-center space-x-8">
          <a href="../index.html" class="nav-link">Text2SQL Hub</a>
          <a href="../what-is-text2sql.html" class="nav-link">What is Text-to-SQL?</a>
          <a href="../approaches.html" class="nav-link active">Solutions</a>
          <a href="../about.html" class="nav-link">About</a>
          <a href="../consulting.html" class="btn-primary">Get In Touch</a>
        </div>
      </div>
    </div>
  </nav>

  <!-- Article Header -->
  <section class="article-header">
    <div class="container">
      <div class="max-w-4xl mx-auto">
        <a href="../approaches.html" class="text-white opacity-75 hover:opacity-100 mb-6 inline-block">‚Üê Back to All Solutions</a>

        <h1 class="text-3xl md:text-4xl font-bold mb-6">
          Building SQL-of-Thought: Multi-Agentic Text-to-SQL with Guided Error Correction
        </h1>

        <p class="text-base opacity-90 mb-6">
          A working implementation of the 91% accurate framework using 6 specialized agents, error taxonomy, and chain-of-thought reasoning on real database queries
        </p>

        <!-- Article Meta Info -->
        <div class="article-meta">
          <span>üìÖ January 2025</span>
          <span>‚è±Ô∏è 18 min read</span>
          <span class="difficulty-badge difficulty-advanced">Advanced</span>
        </div>
      </div>
    </div>
  </section>

  <!-- Article Content -->
  <div class="container py-12">
    <div class="article-content">

      <!-- Hero Image -->
      <div class="my-8">
        <img src="../assets/images/sql-of-thought/intro.png" alt="SQL-of-Thought Multi-Agent Framework" class="w-full rounded-lg shadow-lg">
        <p class="text-center text-sm text-secondary mt-2">Image Generated by Author Using AI</p>
      </div>

      <!-- Introduction -->
      <section>
        <p>
          You ask your database: "Show me customers who spent more than average last quarter."
        </p>
        <p>
          The AI generates SQL. Executes it. Returns an error.
        </p>
        <p>
          Tries again. Same error, different phrasing.
        </p>
        <p>
          Third attempt. Still broken.
        </p>
        <p>
          This happens constantly with Text-to-SQL systems. Even GPT-4 fails on complex joins, ambiguous columns, and aggregation logic. Most systems retry blindly, making the same mistakes in slightly different ways.
        </p>
        <p>
          A recent paper from Max Planck Institute and AWS GenAI introduced <strong>SQL-of-Thought, a multi-agent framework</strong> that categorizes 31 types of SQL errors and fixes them systematically. It hits 91.59% accuracy on the Spider benchmark.
        </p>
        <p>
          Instead of just explaining the research, I built a working demo to see how this approach handles real errors.
        </p>
        <p>Here's what I learned.</p>
      </section>

      <!-- Problem Statement -->
      <section>
        <h2><strong>The Problem with Single-Agent Text-to-SQL</strong></h2>
        <p>
          Traditional approaches use one LLM call to generate SQL directly from natural language.
        </p>
        <p>
          When the query fails, they retry. Maybe adjust the prompt. Try again.
        </p>
        <p>
          No systematic understanding of what went wrong. No targeted fix based on error type.
        </p>
        <p><strong>Common failures include:</strong></p>
        <ul>
          <li>Schema mismatches (wrong table or column names)</li>
          <li>Ambiguous column references (same name in multiple tables)</li>
          <li>Missing joins between related tables</li>
          <li>Incorrect aggregation functions</li>
          <li>Wrong filter conditions</li>
        </ul>
        <p>
          The paper's insight: categorize errors into 31 types across 9 categories, then apply targeted corrections based on error classification.
        </p>
      </section>

      <!-- Architecture Overview -->
      <section>
        <h2><strong>Understanding the Paper's Architecture</strong></h2>
        <p>
          Before diving into the demo, here's how SQL-of-Thought actually works.
        </p>

        <div class="my-8">
          <img src="../assets/images/sql-of-thought/architecture.png" alt="Multi-Agent Pipeline" class="w-full rounded-lg shadow-lg">
          <p class="text-center text-sm text-secondary mt-2">Figure 1 from Research Paper - Multi-Agent Pipeline</p>
        </div>

        <h3><strong>The Multi-Agent Pipeline</strong></h3>
        <p>The framework orchestrates six specialized agents in sequence:</p>
        <ol>
          <li><strong>Schema Linking Agent</strong> receives the natural language question and database schema, then identifies relevant tables, columns, primary keys, and foreign key relationships.</li>
          <li><strong>Subproblem Agent</strong> takes the schema-linked output and breaks the query into clause-level components: WHERE conditions, JOIN requirements, GROUP BY aggregations, ORDER BY sorting, HAVING filters, LIMIT clauses.</li>
          <li><strong>Query Plan Agent</strong> uses chain-of-thought reasoning to create a step-by-step execution plan. This agent thinks through the problem procedurally before writing any SQL.</li>
          <li><strong>SQL Agent</strong> converts the query plan into executable SQL, handling syntax and formatting.</li>
          <li><strong>DB Execution Engine</strong> runs the query against the database.</li>
          <li><strong>Correction Loop</strong> activates on failure:
            <ul>
              <li><strong>Correction Plan Agent</strong> analyzes the error using the taxonomy, identifies root cause, generates fix strategy</li>
              <li><strong>Correction SQL Agent</strong> regenerates query based on correction plan</li>
              <li>Loop repeats until success or max attempts reached</li>
            </ul>
          </li>
        </ol>
        <p>
          <strong>The key innovation:</strong> when errors occur, the system doesn't just retry. It diagnoses the error type and applies a targeted fix.
        </p>
      </section>

      <!-- Error Taxonomy -->
      <section>
        <h2><strong>The Error Taxonomy</strong></h2>

        <div class="my-8">
          <img src="../assets/images/sql-of-thought/error-taxonomy.png" alt="Error Taxonomy" class="w-full rounded-lg shadow-lg">
          <p class="text-center text-sm text-secondary mt-2">Figure 2 from Research Paper - Error Taxonomy</p>
        </div>

        <p>
          The correction system categorizes SQL failures into <strong>9 major categories with 31 specific error types</strong>.
        </p>
        <p>
        <div class="my-8">
          <img src="../assets/images/sql-of-thought/table1.png" alt="Error Taxonomy" class="w-full rounded-lg shadow-lg">
          <p class="text-center text-sm text-secondary mt-2">table 1 from Research Paper - Error Taxonomy</p>
        </div>


          Each error code provides concise identification without overwhelming the LLM's context window.
        </p>

        <h3><strong>Why This Taxonomy Matters</strong></h3>
        <p>
          Traditional systems see only execution errors: "<strong>column not found</strong>" or "<strong>ambiguous reference</strong>." They retry with slight variations, often repeating the same mistake.
        </p>
        <p>
          SQL-of-Thought categorizes the error type and applies the known solution pattern. If it's <code>ambiguous_col</code>, add table prefixes. If it's <code>join_missing</code>, identify the join path through foreign keys. If it's <code>agg_no_groupby</code>, add GROUP BY for non-aggregated columns.
        </p>
        <p>
          The taxonomy transforms debugging from guesswork into systematic diagnosis.
        </p>
      </section>

      <!-- Building the Demo -->
      <section>
        <h2><strong>Building the Demo</strong></h2>
        <p>
          I wanted to see this work with real data and real errors.
        </p>

        <h3><strong>Database Choice</strong></h3>
        <p>
          I used Chinook, a SQLite database modeling a music store. It has 11 tables: Artist, Album, Track, Invoice, Customer, Employee, and more. Realistic complexity with foreign keys and multiple join paths.
        </p>

        <h3><strong>Tech Stack</strong></h3>
        <ul>
          <li><strong>Backend:</strong> Node.js + Express + DuckDB (SQLite compatibility)</li>
          <li><strong>Frontend:</strong> Vite + vanilla JavaScript</li>
          <li><strong>LLM:</strong> OpenAI GPT-4o-mini (fast and cost-effective)</li>
          <li><strong>Real-time updates:</strong> Server-Sent Events to stream each agent step</li>
        </ul>
      </section>

      <!-- The 6 Specialized Agents -->
      <section>
        <h2><strong>The 6 Specialized Agents</strong></h2>

        <div class="my-8">
          <img src="../assets/images/sql-of-thought/6_agents.png" alt="Six Specialized Agents" class="w-full rounded-lg shadow-lg">
          <p class="text-center text-sm text-secondary mt-2">Agent Architecture - Image by Author</p>
        </div>

        <p>Following the paper's architecture, I built six specialized agents in Node.js:</p>

        <div class="space-y-6">
          <div class="bg-blue-900 border-l-4 border-blue-500 p-4">
            <h4 class="font-bold text-gray-200 mb-2">1. Schema Linking Agent</h4>
            <p>Identifies relevant tables and columns from the database schema.</p>
            <p>Takes the natural language question and full schema, and returns only the subset needed for the query.</p>
            <p>For "top selling tracks," it identifies Track, InvoiceLine, Album, and Artist tables with their relationships.</p>
          </div>

          <div class="bg-green-900 border-l-4 border-green-500 p-4">
            <h4 class="font-bold text-gray-200 mb-2">2. Subproblem Agent</h4>
            <p>Breaks the question into SQL clause components.</p>
            <p>Takes the question and linked schema, outputs structured breakdown of SELECT, FROM, JOIN, WHERE, GROUP BY, ORDER BY, LIMIT clauses.</p>
            <p><strong>Example breakdown:</strong></p>
            <div class="code-block mt-2">
              <pre><code class="language-json">{
  "SELECT": "Track.Name, SUM(revenue)",
  "FROM": "Track, InvoiceLine",
  "JOIN": "Track.TrackId = InvoiceLine.TrackId",
  "GROUP BY": "Track.Name",
  "ORDER BY": "revenue DESC",
  "LIMIT": "5"
}</code></pre>
            </div>
          </div>

          <div class="bg-purple-900 border-l-4 border-purple-500 p-4">
            <h4 class="font-bold text-gray-200 mb-2">3. Query Plan Agent (Chain-of-Thought)</h4>
            <p>Creates step-by-step execution plan with reasoning for each action.</p>
            <p>Takes question, schema, and subproblems, outputs numbered steps explaining the logic:</p>
            <ul class="mt-2 space-y-1">
              <li><strong>Step 1:</strong> Start with Track table (contains track names)</li>
              <li><strong>Step 2:</strong> JOIN InvoiceLine (links tracks to revenue via TrackId)</li>
              <li><strong>Step 3:</strong> Calculate SUM(UnitPrice √ó Quantity) for total revenue</li>
              <li><strong>Step 4:</strong> GROUP BY Track.Name to aggregate per track</li>
              <li><strong>Step 5:</strong> ORDER BY revenue DESC, LIMIT 5 for top results</li>
            </ul>
            <p class="mt-2">This reasoning step prevents logical errors before SQL generation.</p>
          </div>

          <div class="bg-yellow-900 border-l-4 border-yellow-500 p-4">
            <h4 class="font-bold text-gray-200 mb-2">4. SQL Generation Agent</h4>
            <p>Converts the plan into executable SQL.</p>
            <p>Takes the query plan and schema, outputs syntactically correct SQL with proper table aliases and join conditions.</p>
          </div>

          <div class="bg-gray-800 border-l-4 border-gray-500 p-4">
            <h4 class="font-bold text-gray-200 mb-2">5. SQL Execution</h4>
            <p>Runs the generated SQL against DuckDB.</p>
            <p>Success returns results. Failure captures the error message and triggers correction.</p>
          </div>

          <div class="bg-red-900 border-l-4 border-red-500 p-4">
            <h4 class="font-bold text-gray-200 mb-2">6. Correction Agents (The Critical Innovation)</h4>
            <p>When execution fails, two agents collaborate:</p>
            <ul class="mt-2">
              <li><strong>Correction Plan Agent</strong> runs DESCRIBE queries on problematic tables to inspect the actual schema. It classifies the error using the taxonomy (schema_link.ambiguous_col, join.wrong_condition, etc.) and identifies root cause with fix strategy.</li>
              <li><strong>Correction SQL Agent</strong> applies the fix by rewriting SQL based on the correction plan. It uses actual column names from DESCRIBE output rather than guessing. Maximum 3 correction attempts with different strategies.</li>
            </ul>
            <p class="mt-2">This correction loop is what makes the system robust. No blind retry; diagnostic analysis and targeted repair.</p>
          </div>
        </div>

        <p class="mt-4">
          The UI shows each agent's output in real-time. You watch schema linking, see the query plan being built, view generated SQL, and observe error correction when needed.
        </p>
      </section>

      <!-- Demo 1 -->
      <section>
        <h2><strong>Demo 1: Simple Query Success</strong></h2>
        <p>Let's start with a straightforward query.</p>
        <p><strong>Query:</strong> "What are the top 5 best-selling tracks by total revenue?"</p>

        <div class="my-8">
          <img src="../assets/images/sql-of-thought/demo1.gif" alt="Demo 1 - Simple Query" class="w-full rounded-lg shadow-lg">
          <p class="text-center text-sm text-secondary mt-2">Demo 1 - Simple Query Success - Image by Author</p>
        </div>

        <p><strong>Here's what happens behind the scenes:</strong></p>
        <ol>
          <li><strong>Schema Linking</strong> identifies the tables needed: Track (for names), InvoiceLine (for sales), and the relationship TrackId connecting them.</li>
          <li><strong>Subproblem decomposition</strong> breaks it into: SELECT track name and revenue sum, JOIN Track with InvoiceLine, GROUP BY track name, ORDER BY revenue descending, LIMIT to 5.</li>
          <li><strong>Query Plan</strong> reasons through the logic: start with Track table, join to InvoiceLine via TrackId, calculate revenue as UnitPrice √ó Quantity, aggregate per track, sort by total, take top 5.</li>
          <li><strong>SQL Generation</strong> produces:
            <div class="code-block mt-2">
              <div class="code-header">
                <span class="code-language">SQL</span>
                <button class="copy-button">Copy</button>
              </div>
              <pre><code class="language-sql">SELECT
  t.Name AS TrackName,
  SUM(il.UnitPrice * il.Quantity) AS TotalRevenue
FROM Track t
JOIN InvoiceLine il ON t.TrackId = il.TrackId
GROUP BY t.Name
ORDER BY TotalRevenue DESC
LIMIT 5;</code></pre>
            </div>
          </li>
        </ol>

        <p><strong>Result:</strong> ‚úÖ Success in first attempt. 5 rows returned in 2.8 seconds.</p>
        <p>This shows the pipeline working smoothly when no errors occur.</p>
      </section>

      <!-- Demo 2 -->
      <section>
        <h2><strong>Demo 2: Ambiguous Column Error with Guided Correction</strong></h2>
        <p>Now the interesting part.</p>
        <p><strong>Query:</strong> "Get all invoice items with their unit price and track unit price"</p>

        <div class="my-8">
          <img src="../assets/images/sql-of-thought/demo2.gif" alt="Demo 2 - Error Correction" class="w-full rounded-lg shadow-lg">
          <p class="text-center text-sm text-secondary mt-2">Demo 2 - Ambiguous Column Error - Image Generated by Author</p>
        </div>

        <p><strong>The problem:</strong> Both InvoiceLine and Track tables have a UnitPrice column. The initial SQL failed with "ambiguous column reference."</p>

        <p><strong>How the correction worked:</strong></p>
        <ol>
          <li><strong>Correction Plan Agent</strong> classified the error as <code>schema_link.ambiguous_col</code></li>
          <li>Ran <code>DESCRIBE InvoiceLine</code> and <code>DESCRIBE Track</code> to see actual schemas</li>
          <li>Identified that both tables contain UnitPrice</li>
          <li>Generated fix strategy: add table prefixes to disambiguate</li>
          <li><strong>Correction SQL Agent</strong> regenerated SQL with proper table aliases</li>
        </ol>

        <p><strong>Result:</strong> ‚úÖ Success on second attempt after targeted correction.</p>
      </section>

      <!-- Error Taxonomy in Action -->
      <section>
        <h2><strong>Error Taxonomy in Action</strong></h2>
        <p>Here's how the taxonomy guides corrections for different error types:</p>

        <div class="my-8">
          <img src="../assets/images/sql-of-thought/table2.png" alt="Error Taxonomy in Action" class="w-full rounded-lg shadow-lg">
          <p class="text-center text-sm text-secondary mt-2">Error Categories and Solutions - Image by Author</p>
        </div>

        <p>
          Each category has a known solution pattern. The correction agent identifies the category and applies the appropriate fix.
        </p>
      </section>

      <!-- Why It Works -->
      <section>
        <h2><strong>Why This Approach Works</strong></h2>

        <div class="space-y-4">
          <div>
            <h3 class="font-bold text-xl mb-2">Systematic Error Handling</h3>
            <p>Instead of random retry, each error type has a diagnostic procedure and fix strategy. The agent knows what to check and how to repair it.</p>
          </div>

          <div>
            <h3 class="font-bold text-xl mb-2">Dynamic Schema Inspection</h3>
            <p>The correction agent runs DESCRIBE queries to see actual table structures. No hardcoded schema knowledge; it adapts to any database.</p>
          </div>

          <div>
            <h3 class="font-bold text-xl mb-2">Multi-Agent Collaboration</h3>
            <p>Each agent specializes:</p>
            <ul>
              <li>Schema linking focuses on identifying relevant tables</li>
              <li>Query planning focuses on logical flow</li>
              <li>SQL generation focuses on syntax</li>
              <li>Correction focuses on debugging</li>
            </ul>
            <p>This separation reduces cognitive load on each LLM call.</p>
          </div>

          <div>
            <h3 class="font-bold text-xl mb-2">Transparency</h3>
            <p>Users see every step. When errors occur, they understand what went wrong and how it was fixed. This builds trust in the system.</p>
          </div>
        </div>
      </section>

      <!-- Limitations -->
      <section>
        <h2><strong>Limitations and Tradeoffs</strong></h2>

        <div class="space-y-6">
          <div>
            <h3 class="font-bold text-xl mb-2">1. No Value Retrieval Agent</h3>
            <p>The paper's agents don't retrieve sample data from tables to inform filtering decisions.</p>
            <p><strong>Example limitation:</strong> For "show me customers in California," the system must guess whether the database uses "California," "CA," "calif," or another variant.</p>
            <p>A value retrieval agent could run:</p>
            <div class="code-block mt-2">
              <pre><code class="language-sql">SELECT DISTINCT State FROM Customer LIMIT 20;</code></pre>
            </div>
            <p>This would show actual values: ["CA", "NY", "TX"‚Ä¶] and inform the WHERE clause construction.</p>
            <p><strong>Without this, queries fail when:</strong></p>
            <ul>
              <li>State abbreviations vs full names differ from user's phrasing</li>
              <li>Date formats are ambiguous (MM/DD/YYYY vs YYYY-MM-DD)</li>
              <li>Category names use internal codes ("cat_001" vs "Electronics")</li>
              <li>Case sensitivity matters ("active" vs "Active")</li>
            </ul>
          </div>

          <div>
            <h3 class="font-bold text-xl mb-2">2. Token Costs</h3>
            <p>Multi-agent architecture uses more tokens than single-call approaches. The demo averaged:</p>
            <ul>
              <li>Simple query: ~2,000 tokens ($0.003)</li>
              <li>Complex query with correction: ~5,500 tokens ($0.008)</li>
            </ul>
            <p>Production systems would need cost optimization through hybrid models (reasoning models for planning, cheaper models for execution).</p>
          </div>

          <div>
            <h3 class="font-bold text-xl mb-2">3. Latency</h3>
            <p>Six agent calls take longer than one call. Average end-to-end time:</p>
            <ul>
              <li>Single-agent baseline: 1.8 seconds</li>
              <li>SQL-of-Thought: 4.2 seconds</li>
            </ul>
            <p>The accuracy gain justifies the latency for most use cases.</p>
          </div>
        </div>
      </section>

      <!-- Future Improvements -->
      <section>
        <h2><strong>Future Improvements</strong></h2>
        <p>Several directions could enhance the demo:</p>
        <ul>
          <li><strong>Fine-tuned models</strong> for specific agent roles. A small model trained on schema linking could reduce costs while maintaining accuracy.</li>
          <li><strong>Query execution plan visualization.</strong> Show users how the database actually executes the generated SQL, not just the SQL itself.</li>
          <li><strong>Support for more databases.</strong> PostgreSQL, MySQL, SQL Server each have dialect-specific quirks that need custom correction strategies.</li>
          <li><strong>Interactive correction guidance.</strong> Let users provide hints when automatic correction fails, teaching the system new error patterns.</li>
          <li><strong>Performance optimization tracking.</strong> Not just correctness; also measure query execution time and suggest index improvements.</li>
        </ul>
      </section>

      <!-- Conclusion -->
      <section>
        <h2><strong>Conclusion</strong></h2>

        <div class="my-8">
          <img src="../assets/images/sql-of-thought/conclusion.png" alt="SQL-of-Thought Conclusion" class="w-full rounded-lg shadow-lg">
          <p class="text-center text-sm text-secondary mt-2">Image Generated by Author Using AI</p>
        </div>

        <p>
          The SQL-of-Thought paper introduces a practical framework for reliable Text-to-SQL translation.
        </p>
        <p>
          The key insight: <strong>categorize errors systematically and apply targeted fixes based on error type</strong>. This transforms SQL generation from a trial-and-error process into a diagnostic system.
        </p>
        <p>
          Building the demo confirmed that multi-agent architecture with taxonomy-guided correction works on real data. The approach handles ambiguous columns, missing joins, wrong aggregations, and other common failures that break single-agent systems.
        </p>
        <p>
          The 91.59% accuracy on the Spider benchmark isn't just a number. It represents a systematic approach to error handling that makes Text-to-SQL reliable enough for production use.
        </p>
      </section>

      <!-- GitHub Link -->
      <section class="consulting-cta p-8 md:p-12 rounded-2xl my-12">
        <h2 class="text-white text-center mb-4">Try It Yourself</h2>
        <p class="text-xl text-center mb-8 opacity-90">
          Full source code and working demo available on GitHub
        </p>
        <div class="flex justify-center gap-4">
          <a href="https://github.com/MKcodeshere/sql-of-thought-demo" target="_blank" class="btn-primary text-blue-600 hover:bg-gray-800">
            View on GitHub ‚Üí
          </a>
        </div>
      </section>

      <!-- Consulting CTA -->
      <div class="consulting-cta">
        <h3>Need Help Implementing Multi-Agent Text-to-SQL?</h3>
        <p>I offer consulting services for advanced Text-to-SQL systems. Let's discuss your requirements.</p>
        <a href="../consulting.html" class="btn-primary text-blue-600 hover:bg-gray-800">
          Schedule a Consultation
        </a>
      </div>

    </div>
  </div>

  <!-- Footer -->
  <footer>
    <div class="container">
      <div class="grid md:grid-cols-3 gap-8 mb-8">
        <div>
          <h3 class="text-xl font-bold mb-4">Text2SQLHub</h3>
          <p class="text-gray-400">Your comprehensive guide to Text-to-SQL systems with GenAI.</p>
        </div>
        <div class="footer-links">
          <h3 class="text-xl font-bold mb-4">Quick Links</h3>
          <ul class="space-y-2">
            <li><a href="../index.html">Text2SQL Hub</a></li>
            <li><a href="../what-is-text2sql.html">What is Text-to-SQL?</a></li>
            <li><a href="../approaches.html">All Solutions</a></li>
            <li><a href="../about.html">About</a></li>
            <li><a href="../consulting.html">Consulting</a></li>
          </ul>
        </div>
        <div>
          <h3 class="text-xl font-bold mb-4">Connect</h3>
          <p class="text-gray-400 text-sm">your@email.com</p>
        </div>
      </div>
      <div class="border-t border-gray-700 pt-6 text-center text-gray-400 text-sm">
        <p>&copy; 2025 Text2SQLHub. Built with ‚ù§Ô∏è for the AI and Text-to-SQL community.</p>
      </div>
    </div>
  </footer>

  <!-- Scripts -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-sql.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-json.min.js"></script>
  <script src="../assets/js/main.js"></script>

</body>
</html>
